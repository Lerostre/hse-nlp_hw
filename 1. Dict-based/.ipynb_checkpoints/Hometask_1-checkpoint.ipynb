{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LrdL__lCtr6M"
   },
   "source": [
    "## Базовые требования к домашкам\n",
    "\n",
    "1. Формат - jupyter-тетрадка или скрипт на питоне\n",
    "2. Мы запускаем ваши тетрадки с нуля, поэтому следите, чтобы не было \n",
    "- необъявленных переменных (удалили ячейку, а переменная продолжает использоваться)\n",
    "- лишних принтов отладочной информации\n",
    "3. Комментарии приветствуются!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r_CzjN-StydR"
   },
   "source": [
    "## Задание\n",
    "В рамках этого задания мы будем создавать программу, которая получая на вход отзыв, будет предсказывать, является отзыв положительным или отрицательным. Делать мы будем это таким образом: мы возьмём некоторое число заранее размеченных как положительные или отрицательные отзывов, выделим те слова, которые встречаются только в положительных или только в отрицательных отзывах, и будем считать, каких слов  в поступившем нам на проверку отзыве больше.\n",
    "\n",
    "\n",
    "Мы будем работать по заранее определённому пайплайну:\n",
    "\n",
    "1.  Сначала нам надо скачать дату -- соберите как минимум 60 (30 положительных  и 30 отрицательных) отзывов на похожие продукты (не надо мешать отзывы на отели с отзывами на ноутбуки) для составления \"тонального словаря\" (чем больше отзывов, тем лучше)  и 10 отзывов для проверки качества.   (2 балла в случае сбора путём парсинга, 1 - если найдете уже готовые данные или просто закопипастите без парсинга)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Токенизируйте слова,  приведите их к нижнему регистру и к начальной форме  (1 балл за токенизацию, 1 - за начальную форму)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "russian_stopwords = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    sents = nltk.sent_tokenize(text)\n",
    "    tokens = nltk.word_tokenize(sents)\n",
    "    lemmas = [lemmatizer.lemmatize(x) for x in tokens]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Составьте 2 множества - в одном будут слова, которые встречаются только в положительных отзывах, а в другом - встречающиеся только в отрицательных. Попробуйте поиграть с частотностями и исключить шум (к примеру, выбросить слова, встречающиеся 1-2 раза) (2 балла) (если у вас получились пустые множества, уберите фильтр по частотности или увеличьте выборку)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y = X.sentiment\n",
    "X = X.drop(y, axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=671)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"processed\"] = X.text.spply(lambda x: preprocess(x))\n",
    "\n",
    "# это надо делать не для всех, а только для трейна\n",
    "good_words = X_train[X_train.sentiment == 1].processed\n",
    "bad_words = X_train[X_train.sentiment == 0].processed\n",
    "# здесь нужно исключающее или"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def reduce_noise(words, n):\n",
    "    noise = Counter(words).most_common()\n",
    "    return noise[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Создайте функцию, которая будет определять, положительный ли отзыв или отрицательный в зависимости от того, какие слова встретились в нём, и посчитайте качество при помощи accuracy (1  - за коректно работающую функцию, 1 - за подсчёт accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_prediction(lemmas):\n",
    "    score = 0\n",
    "    \n",
    "    for lemma in lemmas:\n",
    "        if lemma in good_words: score += 1 else -1\n",
    "        \n",
    "    return max(0, sign(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = X_test.apply(lambda x: sentiment_prediction(x))\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Предложите как минимум 2 способа улучшить эту программу с помощью добавления к ней любых мулек (1 балл за описание словами, 2 - если реализуете хотя бы один способ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно сделать много чего:\n",
    "\n",
    "1. Выборка не очень большая, вполне возможно, что какие-то \"хорошие\" или \"плохие\" слова мы не учли, или учли что-то лишнее, это решается просто - надо скачать побольше. Но возможность того, что слово употреблено в каком-то другом значении остаётся.\n",
    "2. Из текстов не выкинуты стоп-слова и прочий мусор, но скорее всего это не страшно, вряд ли они влияют на тональность, хотя кто знает\n",
    "3. Получившийся алгоритм слишком простой. На самом деле тональность не делится строго бинарно, она может быть смешанная, может быть наполовину негативная и т.д. В идеале нужно учитывать ещё и вероятность, но без эмбеддингов это тяжеловато, можно их обучить или позаимствовать\n",
    "3. Строго говоря, мы никак не смотрим на само значение слова, а только лишь на его форму. Это решается применением w2v, тогда можно косинусно сравнивать с \"хорошими\"/\"плохими\" словами, качество должно быть получше"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOhO9ANVm4SXK9q5vI0e+E4",
   "collapsed_sections": [],
   "name": "Hometask 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
