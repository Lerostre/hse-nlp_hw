{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "075a2cbe-5b51-40e4-b54a-4fabbfbfa3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575f87e2-24f2-4557-ad70-b775af344c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_csv(\"maestro_vk.csv\", index_col=0),\n",
    "                pd.read_csv(\"maestro_blog.csv\", index_col=0),\n",
    "                pd.read_csv(\"maestro_books.csv\", index_col=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a6ce6914-8275-48ff-9505-6b3c561186e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from razdel import sentenize\n",
    "\n",
    "\n",
    "def sentify(df):\n",
    "    df[\"sentence\"] = df.text.apply(lambda y: [x.text for x in sentenize(y)])\n",
    "    df = df.explode(\"sentence\").reset_index(drop=True).drop(\"text\", axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e989e282-6fb4-40f1-a588-ccac804613ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name in [f\"maestro_{i}.csv\" for i in [\"vk\", \"blog\", \"books\"]]:\n",
    "    df = pd.read_csv(df_name, index_col=0)\n",
    "    sentify(df).to_csv(f\"sent_{df_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "70924b08-5256-4399-9b19-c1d115ab9cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_csv(\"sent_maestro_vk.csv\", index_col=0),\n",
    "                pd.read_csv(\"sent_maestro_blog.csv\", index_col=0),\n",
    "                pd.read_csv(\"sent_maestro_books.csv\", index_col=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8e5be506-dc94-43dd-abd6-9e7772d20bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-kutuzovskii-p...</td>\n",
       "      <td>Кутузовский план Кремля (27. 12. 2011). Запись...</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>Начну, простите, с конца.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-kutuzovskii-p...</td>\n",
       "      <td>Кутузовский план Кремля (27. 12. 2011). Запись...</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>Да, митинги 10-го и 24-го декабря – это замеча...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-kutuzovskii-p...</td>\n",
       "      <td>Кутузовский план Кремля (27. 12. 2011). Запись...</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>У России был один приближенный к серьезному ша...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-kutuzovskii-p...</td>\n",
       "      <td>Кутузовский план Кремля (27. 12. 2011). Запись...</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>Немного снижая пафос, можно было бы вспомнить ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-kutuzovskii-p...</td>\n",
       "      <td>Кутузовский план Кремля (27. 12. 2011). Запись...</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>Собственно на этом я бы и завершил статью, одн...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://vk.com/@evgenyponasenkov-kutuzovskii-p...   \n",
       "1  https://vk.com/@evgenyponasenkov-kutuzovskii-p...   \n",
       "2  https://vk.com/@evgenyponasenkov-kutuzovskii-p...   \n",
       "3  https://vk.com/@evgenyponasenkov-kutuzovskii-p...   \n",
       "4  https://vk.com/@evgenyponasenkov-kutuzovskii-p...   \n",
       "\n",
       "                                               title        date  \\\n",
       "0  Кутузовский план Кремля (27. 12. 2011). Запись...  2021-02-24   \n",
       "1  Кутузовский план Кремля (27. 12. 2011). Запись...  2021-02-24   \n",
       "2  Кутузовский план Кремля (27. 12. 2011). Запись...  2021-02-24   \n",
       "3  Кутузовский план Кремля (27. 12. 2011). Запись...  2021-02-24   \n",
       "4  Кутузовский план Кремля (27. 12. 2011). Запись...  2021-02-24   \n",
       "\n",
       "                                            sentence  \n",
       "0                          Начну, простите, с конца.  \n",
       "1  Да, митинги 10-го и 24-го декабря – это замеча...  \n",
       "2  У России был один приближенный к серьезному ша...  \n",
       "3  Немного снижая пафос, можно было бы вспомнить ...  \n",
       "4  Собственно на этом я бы и завершил статью, одн...  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"sent_combined.csv\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2bd8848c-9bc8-4d6d-b196-160eb1bd7069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'[^\\d\\W]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcfd699-4642-41b6-a019-48be6ba0fb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class :\n",
    "    def __init__(self, v=None):\n",
    "        self.v = v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590df9db-e0f1-4296-819b-3b2a681e8333",
   "metadata": {},
   "source": [
    "Быстрее всего искать что-либо в хешированных структурах, так что в идеале жолжен быть сет, либо хотя бы словрь. Словарь хорош тем, что в него можно сразу затолкать лемму и разбор слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "ba2f0466-427c-4e2d-b56c-15fe2a265656",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "df2 = pd.DataFrame({\"token\":[], \"lemma\":[] , \"pos\":[], \"tag\":[]})\n",
    "\n",
    "def preprocess(text):\n",
    "    global i\n",
    "    global df2\n",
    "    \n",
    "    lowered = tokenizer.tokenize(text.lower())\n",
    "    forms = predictor.predict(lowered)\n",
    "    tokens = {}\n",
    "    lemmas = {}\n",
    "    for form in forms:\n",
    "        word = form.word\n",
    "        lemma = form.normal_form\n",
    "        \n",
    "        if word in tokens:\n",
    "            tokens[word] += [i]\n",
    "        else:\n",
    "            tokens.update({word: [i]})\n",
    "            \n",
    "        if lemma in lemmas:\n",
    "            lemmas[lemma] += [i]\n",
    "        else:\n",
    "            lemmas.update({lemma: [i]})\n",
    "            \n",
    "        df2 = pd.concat([df2, pd.DataFrame({\"token\": word,\n",
    "                                            \"lemma\": lemma,\n",
    "                                            \"pos\": form.pos,\n",
    "                                            \"tag\": form.tag\n",
    "                                           },\n",
    "                                            index=[i])])\n",
    "        i += 1\n",
    "\n",
    "    return tokens, lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae521e7-fb59-4848-8e06-3c7c02ecce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# в основном датафрейме храню только список токенов\n",
    "# по нему будет искаться быстро, если нашёлся, беру номер предложения\n",
    "# залетаю в токены, беру значение токена, это будет индекс в бд морфологии\n",
    "# достаю из морфологии всю инфу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ab8022-1743-4054-a15a-2f5512d6a2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%capture\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "t = pd.DataFrame(df.sentence.apply(preprocess).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "970bc3a9-6eac-4173-a666-0f1065b6cc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "t[\"lemmas\"] = t[0].apply(lambda x: x[\"lemmas\"])\n",
    "t[\"tokens\"] = t[0].apply(lambda x: x[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "75e0796f-ff33-40a6-a22c-a2430beb47d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'tokens': {'начну': [84], 'простите': [85], '...</td>\n",
       "      <td>{'начать': [84], 'простить': [85], 'с': [86], ...</td>\n",
       "      <td>{'начну': [84], 'простите': [85], 'с': [86], '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'tokens': {'да': [88, 99], 'митинги': [89], '...</td>\n",
       "      <td>{'да': [88, 99], 'митинг': [89], 'го': [90, 92...</td>\n",
       "      <td>{'да': [88, 99], 'митинги': [89], 'го': [90, 9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  {'tokens': {'начну': [84], 'простите': [85], '...   \n",
       "1  {'tokens': {'да': [88, 99], 'митинги': [89], '...   \n",
       "\n",
       "                                              lemmas  \\\n",
       "0  {'начать': [84], 'простить': [85], 'с': [86], ...   \n",
       "1  {'да': [88, 99], 'митинг': [89], 'го': [90, 92...   \n",
       "\n",
       "                                              tokens  \n",
       "0  {'начну': [84], 'простите': [85], 'с': [86], '...  \n",
       "1  {'да': [88, 99], 'митинги': [89], 'го': [90, 9...  "
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d29e4c-84ba-47db-9818-58c56ec9455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(1000) - 1m30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "eaa7259c-c95f-48f3-a901-b47e96334e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.DataFrame(t.tolist(), index= t.index, columns=[\"tokens\", \"lemmas\", \"morph_info\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "5afd3b83-f2db-48e3-82eb-510b7b26f833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'tokens': {'начну': [84], 'простите': [85], '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'tokens': {'да': [88, 99], 'митинги': [89], '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  {'tokens': {'начну': [84], 'простите': [85], '...\n",
       "1  {'tokens': {'да': [88, 99], 'митинги': [89], '..."
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "505dde39-b05a-44c4-99a5-8649eccf2af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"начну\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "7c81efea-7cca-4fa4-be1e-2ae77dc952cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_search(word, df=df, df2=df2):\n",
    "    v = np.vectorize(lambda x: word in x)\n",
    "    indices = np.where(v(df[\"tokens\"]) == True)[0]\n",
    "    \n",
    "    for i in indices:\n",
    "        print(i)\n",
    "        print(df.iloc[i][\"sentence\"])\n",
    "        morph = df2.iloc[i]\n",
    "        print(f\"\"\"\\tnormal form - {morph.lemma}\n",
    "        pos - {morph.pos}\n",
    "        tag - {morph.tag}\"\"\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "e5abd794-d022-454b-944d-4216fa9386e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Конечно, не обошлось и без дипломированных лицедеев – актрисы Натальи Селезневой и актера Валерия Баринова.\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[398][\"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "d8de44e4-086b-4294-8372-479a21753c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Начну, простите, с конца.\n",
      "\tnormal form - начать\n",
      "        pos - VERB\n",
      "        tag - Mood=Ind|Number=Sing|Person=1|Tense=Notpast|VerbForm=Fin|Voice=Act\n",
      "\n",
      "308\n",
      "Начну не с того, что правительство России не выбрало в качестве повода к празднику «народного единства».\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [663]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mword_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [662]\u001b[0m, in \u001b[0;36mword_search\u001b[1;34m(word, df, df2)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m----> 8\u001b[0m morph \u001b[38;5;241m=\u001b[39m \u001b[43mdf2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mnormal form - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmorph\u001b[38;5;241m.\u001b[39mlemma\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124mpos - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmorph\u001b[38;5;241m.\u001b[39mpos\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124mtag - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmorph\u001b[38;5;241m.\u001b[39mtag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    964\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    966\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1520\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1519\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m-> 1520\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1452\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1450\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[0;32m   1451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[1;32m-> 1452\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "word_search(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "d0e306e1-0ab8-4b44-b0a6-de365cfc2d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 998 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [начну, начать, VERB, Mood=Ind|Number=Sing|Per...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "v = np.vectorize(lambda x: word in x)\n",
    "\n",
    "indices = np.where(v(t[\"tokens\"]) == True)\n",
    "\n",
    "t.iloc[indices][\"tokens\"].apply(lambda x: df2.iloc[x[word]].values[0])\n",
    "#chars = s.iloc[indices][\"lemmas\"].apply(lambda x: x[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "6d81f145-5643-4945-8ab2-69d83a76d636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начну, простите, с конца.\n",
      "\tnormal form - начать\n",
      "        pos - VERB\n",
      "        tag - Mood=Ind|Number=Sing|Person=1|Tense=Notpast|VerbForm=Fin|Voice=Act\n",
      "Да, митинги 10-го и 24-го декабря – это замечательная веха отечественной истории, да, прежде всего, это дыхание весны и романтики (я вообще вижу в них, прежде всего, художественный смысл), но (не хочу оказаться правым) ОНИ вам ничего не отдадут.\n",
      "\tnormal form - простить\n",
      "        pos - VERB\n",
      "        tag - Mood=Imp|Number=Plur|Person=2|VerbForm=Fin|Voice=Act\n"
     ]
    }
   ],
   "source": [
    "j = [0, 1]\n",
    "\n",
    "for i in j:\n",
    "    print(df.iloc[i][\"sentence\"])\n",
    "    morph = df2.iloc[i]\n",
    "    print(f\"\"\"\\tnormal form - {morph.lemma}\n",
    "        pos - {morph.pos}\n",
    "        tag - {morph.tag}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "ce2206b2-cba2-4930-88ba-d3cb1dc52fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>84</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>начну</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      84\n",
       "0  начну"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.iloc[indices][\"tokens\"].apply(lambda x: df2[\"token\"].iloc[x[word]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "ee45fe7f-a38d-4682-8830-b0822bb08ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.concat([df.iloc[:1000].sentence, s], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "557a93ad-705f-4acc-9cc1-9e1492a2a365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB',\n",
       "        'VERB', 'VERB', 'VERB'], dtype='<U4'),\n",
       " array(['Mood=Ind|Number=Sing|Person=1|Tense=Notpast|VerbForm=Fin|Voice=Act',\n",
       "        'Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act',\n",
       "        'Mood=Ind|Number=Plur|Person=3|Tense=Notpast|VerbForm=Fin|Voice=Act',\n",
       "        'Mood=Ind|Number=Sing|Person=1|Tense=Notpast|VerbForm=Fin|Voice=Act',\n",
       "        'Mood=Ind|Number=Plur|Person=1|Tense=Notpast|VerbForm=Fin|Voice=Act',\n",
       "        'Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act',\n",
       "        'Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act',\n",
       "        'Gender=Fem|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act',\n",
       "        'VerbForm=Inf',\n",
       "        'Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act',\n",
       "        'Mood=Ind|Number=Sing|Person=3|Tense=Notpast|VerbForm=Fin|Voice=Act'],\n",
       "       dtype='<U66'))"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.vectorize(lambda x: (x[\"pos\"], x[\"tag\"]))\n",
    "v(chars.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad905f3b-c806-493f-a21e-e1574c40c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "3 ms - занимает поиск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e170f0e-f6a5-4e36-bab2-97ce26b95904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 колонки, сначала ищу по датафрейму, это супербыстро с векторайзом, потом в каждой строке ищу индекс один раз, вывожу всю инфу из 4 колонок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eab0ad-66e4-4b67-a3cb-0eb77979eb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply - 188 ms vs vectorize - 15 ms\n",
    "# подход со словарём уоскрил в 3 раза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "a638394b-107d-487e-a3ea-d495728519ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0], dtype=int64),)"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "43a62c80-9ab2-44d8-bd2d-4b0f6fdbf7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"да\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "4def3e57-c4e9-466e-998d-760c7e19e622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     {'pos': 'CONJ', 'tag': '_'}\n",
      "12    {'pos': 'CONJ', 'tag': '_'}\n",
      "22    {'pos': 'CONJ', 'tag': '_'}\n",
      "30    {'pos': 'CONJ', 'tag': '_'}\n",
      "47    {'pos': 'CONJ', 'tag': '_'}\n",
      "Name: tokens, dtype: object\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "print(s[[\"tokens\"]].iloc[indices][\"tokens\"].apply(lambda x: x[word]))\n",
    "print(\"!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "a53674b2-66f5-4510-bd1e-c6632a19b6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# думаю, что так лучше всего, тогда можно по индексу сразу найти предложение, его вывести\n",
    "# в соотв колонке сразу обратиться по ключу, достать морфоприколы + лемму\n",
    "# но нужно сделать что-то подобное с другим словарём тоже\n",
    "\n",
    "# или сделать другую бд, но искать-же всё равно надо по хэшу, а где мне его ещё достать\n",
    "# обязательно должно что-то на что-то ссылаться\n",
    "# наверное надо всё-таки хранить лемму в токене тоже и наоборот\n",
    "# токены надо хранить в сете, иначе я их буду долго искать\n",
    "\n",
    "# судя по всему список позов тоже нужно хранить, но там нужен только сет,\n",
    "# чтобы достать форму+поз я посмотрю по словарю\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7274d25d-a98a-4ac3-a025-41540f485ff3",
   "metadata": {},
   "source": [
    "А если всё-таки всё разбить? Искать слово. Допустим, нашёл, вернул индекс, написал предложение + всё, что просят. Вроде так максимально просто. Если поиск в пандасе такой же быстрый как в словаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3c58ccf9-cba3-4506-b2dc-3ac84a2e8996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnnmorph.predictor import RNNMorphPredictor\n",
    "\n",
    "predictor = RNNMorphPredictor(language=\"ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "06c5b593-875d-48df-8f34-87028906fd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "NOUN\n",
      "Case=Nom|Gender=Fem|Number=Sing\n",
      "мама\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'мама'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forms = predictor.predict([\"мама\", \"мыла\", \"раму\"])\n",
    "print(forms[0].pos)\n",
    "print(forms[0].tag)\n",
    "print(forms[0].normal_form)\n",
    "forms[0].word"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
